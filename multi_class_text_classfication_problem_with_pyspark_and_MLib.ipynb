{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mntvi5NgrCg",
        "outputId": "1093f679-e02c-4645-9e67-4ed92091b6d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317145 sha256=b252f72c294676e453f0bf10874bb67a73115491cb5f31de393d113ef4325ada\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark py4j"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho6CJp-Uknja",
        "outputId": "cbce226c-68c4-450a-8160-f05bdf3cd98f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark"
      ],
      "metadata": {
        "id": "qY_LQUaek481"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "findspark.init()"
      ],
      "metadata": {
        "id": "oN0BBYvfk_Py"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession, SQLContext\n",
        "from pyspark import SparkContext"
      ],
      "metadata": {
        "id": "MuscfoTmlA_6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext()\n",
        "sqlcon = SQLContext(sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6C6RRnblNZb",
        "outputId": "35c2899e-e753-4f92-c48e-86efef293db2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "dOKhxhEOlck2",
        "outputId": "fc7d7f88-06ef-4357-d48f-34af22681f95"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://60b8801a0c0c:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = sqlcon.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('train.csv')"
      ],
      "metadata": {
        "id": "Y_OjrBD1lfoe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koa83RitlyDF",
        "outputId": "34a2d10b-657d-4fd6-fcb3-13847bee5e50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------+--------------------+---------+----------+--------------+--------------------+-------------------+------------------+\n",
            "|              Dates|      Category|            Descript|DayOfWeek|PdDistrict|    Resolution|             Address|                  X|                 Y|\n",
            "+-------------------+--------------+--------------------+---------+----------+--------------+--------------------+-------------------+------------------+\n",
            "|2015-05-13 23:53:00|      WARRANTS|      WARRANT ARREST|Wednesday|  NORTHERN|ARREST, BOOKED|  OAK ST / LAGUNA ST|  -122.425891675136|  37.7745985956747|\n",
            "|2015-05-13 23:53:00|OTHER OFFENSES|TRAFFIC VIOLATION...|Wednesday|  NORTHERN|ARREST, BOOKED|  OAK ST / LAGUNA ST|  -122.425891675136|  37.7745985956747|\n",
            "|2015-05-13 23:33:00|OTHER OFFENSES|TRAFFIC VIOLATION...|Wednesday|  NORTHERN|ARREST, BOOKED|VANNESS AV / GREE...|   -122.42436302145|  37.8004143219856|\n",
            "|2015-05-13 23:30:00| LARCENY/THEFT|GRAND THEFT FROM ...|Wednesday|  NORTHERN|          NONE|1500 Block of LOM...|-122.42699532676599| 37.80087263276921|\n",
            "|2015-05-13 23:30:00| LARCENY/THEFT|GRAND THEFT FROM ...|Wednesday|      PARK|          NONE|100 Block of BROD...|  -122.438737622757|37.771541172057795|\n",
            "+-------------------+--------------+--------------------+---------+----------+--------------+--------------------+-------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_list = ['Dates','DayOfWeek','PdDistrict','Resolution','Address','X','Y']\n",
        "data = data.select([column for column in data.columns if column not in drop_list])\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H_-a-scnSLX",
        "outputId": "d771dc7d-abe7-482e-a47a-28b9c90f79fd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------------+\n",
            "|      Category|            Descript|\n",
            "+--------------+--------------------+\n",
            "|      WARRANTS|      WARRANT ARREST|\n",
            "|OTHER OFFENSES|TRAFFIC VIOLATION...|\n",
            "|OTHER OFFENSES|TRAFFIC VIOLATION...|\n",
            "| LARCENY/THEFT|GRAND THEFT FROM ...|\n",
            "| LARCENY/THEFT|GRAND THEFT FROM ...|\n",
            "+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "data.groupBy(\"Category\").count().orderBy(col('count')).show(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWndq__noDXv",
        "outputId": "50530da3-46a4-4f18-bead-57188bbf87e3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+\n",
            "|            Category| count|\n",
            "+--------------------+------+\n",
            "|                TREA|     6|\n",
            "|PORNOGRAPHY/OBSCE...|    22|\n",
            "|            GAMBLING|   146|\n",
            "|SEX OFFENSES NON ...|   148|\n",
            "|           EXTORTION|   256|\n",
            "|             BRIBERY|   289|\n",
            "|          BAD CHECKS|   406|\n",
            "|     FAMILY OFFENSES|   491|\n",
            "|             SUICIDE|   508|\n",
            "|        EMBEZZLEMENT|  1166|\n",
            "|           LOITERING|  1225|\n",
            "|               ARSON|  1513|\n",
            "|         LIQUOR LAWS|  1903|\n",
            "|             RUNAWAY|  1946|\n",
            "|DRIVING UNDER THE...|  2268|\n",
            "|          KIDNAPPING|  2341|\n",
            "|   RECOVERED VEHICLE|  3138|\n",
            "|         DRUNKENNESS|  4280|\n",
            "|  DISORDERLY CONDUCT|  4320|\n",
            "|SEX OFFENSES FORC...|  4388|\n",
            "|     STOLEN PROPERTY|  4540|\n",
            "|            TRESPASS|  7326|\n",
            "|        PROSTITUTION|  7484|\n",
            "|         WEAPON LAWS|  8555|\n",
            "|     SECONDARY CODES|  9985|\n",
            "|FORGERY/COUNTERFE...| 10609|\n",
            "|               FRAUD| 16679|\n",
            "|             ROBBERY| 23000|\n",
            "|      MISSING PERSON| 25989|\n",
            "|      SUSPICIOUS OCC| 31414|\n",
            "|            BURGLARY| 36755|\n",
            "|            WARRANTS| 42214|\n",
            "|           VANDALISM| 44725|\n",
            "|       VEHICLE THEFT| 53781|\n",
            "|       DRUG/NARCOTIC| 53971|\n",
            "|             ASSAULT| 76876|\n",
            "|        NON-CRIMINAL| 92304|\n",
            "|      OTHER OFFENSES|126182|\n",
            "|       LARCENY/THEFT|174900|\n",
            "+--------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, OneHotEncoder, StringIndexer, VectorAssembler, HashingTF, IDF\n",
        "from pyspark.ml.classification import LogisticRegression"
      ],
      "metadata": {
        "id": "4toJrty8ooeQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regextoknizerrr= RegexTokenizer(inputCol=\"Descript\", outputCol=\"words\", pattern=\"\\\\W\" )\n",
        "\n",
        "\n",
        "stopwordsremoverr = StopWordsRemover(inputCol=\"words\" , outputCol=\"filiterd\")\n",
        "\n",
        "CountVectorizerr = CountVectorizer(inputCol=\"filiterd\" , outputCol=\"features\" , vocabSize=10000 , minDF=5)\n",
        "\n",
        "label_string = StringIndexer(inputCol=\"Category\" , outputCol=\"label\")"
      ],
      "metadata": {
        "id": "eAtzN104rkVe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "piplinne = Pipeline(stages=[regextoknizerrr,stopwordsremoverr,CountVectorizerr,label_string])\n",
        "\n",
        "piplinefit = piplinne.fit(data)\n",
        "dataset= piplinefit.transform(data)\n",
        "dataset.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdU22KZWuVaR",
        "outputId": "cb30ab50-ade3-4bb0-c1ad-b6de216a5a8c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|      Category|            Descript|               words|            filiterd|            features|label|\n",
            "+--------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|      WARRANTS|      WARRANT ARREST|   [warrant, arrest]|   [warrant, arrest]|(781,[13,26],[1.0...|  7.0|\n",
            "|OTHER OFFENSES|TRAFFIC VIOLATION...|[traffic, violati...|[traffic, violati...|(781,[8,13,29],[1...|  1.0|\n",
            "|OTHER OFFENSES|TRAFFIC VIOLATION...|[traffic, violati...|[traffic, violati...|(781,[8,13,29],[1...|  1.0|\n",
            "| LARCENY/THEFT|GRAND THEFT FROM ...|[grand, theft, fr...|[grand, theft, lo...|(781,[0,1,2,4],[1...|  0.0|\n",
            "| LARCENY/THEFT|GRAND THEFT FROM ...|[grand, theft, fr...|[grand, theft, lo...|(781,[0,1,2,4],[1...|  0.0|\n",
            "+--------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(traindata,testdata) = dataset.randomSplit([0.75,0.25] , seed=623)\n",
        "\n",
        "print(\"train is\" , traindata.count())\n",
        "print(\"test is\" , testdata.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR6V1DhAwX5U",
        "outputId": "ec2e50b7-df9f-4e45-bdc0-e4eda50fe6a2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train is 659025\n",
            "test is 219024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(maxIter=20 , regParam=0.3, elasticNetParam=0)\n",
        "\n",
        "lrmodel = lr.fit(traindata)"
      ],
      "metadata": {
        "id": "Mpts-2WhyzDw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perdections = lrmodel.transform(testdata)"
      ],
      "metadata": {
        "id": "kbZIDV740CYg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perdections"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gnp373s0-nP",
        "outputId": "11d8abeb-c5e1-4b32-94ab-2b81ad64ccd9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Category: string, Descript: string, words: array<string>, filiterd: array<string>, features: vector, label: double, rawPrediction: vector, probability: vector, prediction: double]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perdections.select(\"Descript\",\"Category\",\"probability\",\"label\",\"prediction\").orderBy(\"probability\", ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPuCo1GM0lWr",
        "outputId": "945cd119-3a96-4417-e9ef-d29dd82ee128"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+--------------------+-----+----------+\n",
            "|            Descript|     Category|         probability|label|prediction|\n",
            "+--------------------+-------------+--------------------+-----+----------+\n",
            "|THEFT, BICYCLE, <...|LARCENY/THEFT|[0.89024284641874...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <...|LARCENY/THEFT|[0.89024284641874...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <...|LARCENY/THEFT|[0.89024284641874...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <...|LARCENY/THEFT|[0.89024284641874...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <...|LARCENY/THEFT|[0.89024284641874...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <...|LARCENY/THEFT|[0.89024284641874...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <...|LARCENY/THEFT|[0.89024284641874...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <...|LARCENY/THEFT|[0.89024284641874...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <...|LARCENY/THEFT|[0.89024284641874...|  0.0|       0.0|\n",
            "|THEFT, GRAND, BY ...|LARCENY/THEFT|[0.88703324369410...|  0.0|       0.0|\n",
            "|THEFT, GRAND, BY ...|LARCENY/THEFT|[0.88703324369410...|  0.0|       0.0|\n",
            "|THEFT, GRAND, BY ...|LARCENY/THEFT|[0.88703324369410...|  0.0|       0.0|\n",
            "|THEFT, GRAND, BY ...|LARCENY/THEFT|[0.88703324369410...|  0.0|       0.0|\n",
            "|THEFT, GRAND, BY ...|LARCENY/THEFT|[0.88703324369410...|  0.0|       0.0|\n",
            "|THEFT, GRAND, BY ...|LARCENY/THEFT|[0.88703324369410...|  0.0|       0.0|\n",
            "|THEFT, GRAND, BY ...|LARCENY/THEFT|[0.88703324369410...|  0.0|       0.0|\n",
            "|THEFT, GRAND, BY ...|LARCENY/THEFT|[0.88703324369410...|  0.0|       0.0|\n",
            "|PETTY THEFT COIN ...|LARCENY/THEFT|[0.85899498329792...|  0.0|       0.0|\n",
            "|PETTY THEFT COIN ...|LARCENY/THEFT|[0.85899498329792...|  0.0|       0.0|\n",
            "|PETTY THEFT COIN ...|LARCENY/THEFT|[0.85899498329792...|  0.0|       0.0|\n",
            "+--------------------+-------------+--------------------+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "print(evaluator.evaluate(perdections))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNc8Om6f1KXl",
        "outputId": "f6ad6051-58e4-4b24-c568-6463c813f70c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9736743524003013\n"
          ]
        }
      ]
    }
  ]
}